<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>PhotoVerse</title>
<link href="./AnimateDiff_files/style.css" rel="stylesheet">
<script type="text/javascript" src="./AnimateDiff_files/jquery.mlens-1.0.min.js"></script> 
<script type="text/javascript" src="./AnimateDiff_files/jquery.js"></script>


<style>
  p.serif{
    font-family:"Times New Roman", Times, serif;
  }
  p.sansserif{
    font-family: Arial, Helvetica, sans-serif;
  }
</style>
  
</head>



<body>
<div class="content">
  <h1><strong>  PhotoVerse: Tuning-Free Image Customization with Text-to-Image Diffusion Models</strong></h1>
  <p id="authors" class="serif">
    <a href="mailto:chenli.phd@bytedance.com">Li Chen<sup>1*</sup></a>
    <a href="mailto:zhaomengyi@buaa.edu.cn">Mengyi Zhao<sup>1,2*</sup></a>
    <a href="mailto:liuyiheng.yolo@bytedance.com">Yiheng Liu<sup>1*</sup></a>
    <a>Mingxu Ding<sup>1</sup></a>
    <a>Yangyang Song<sup>1</sup></a>
    <br>
    <a>Shizun Wang<sup>1,3</sup></a>
    <a>Xu Wang<sup>1</sup></a>
    <a>Hao Yang<sup>1</sup></a>
    <a>Jing Liu<sup>1</sup></a >
    <a>Daniel K. Du<sup>1</sup></a>
    <a>Min Zheng<sup>1</sup></a>
    <br>
    <a style="font-size: 0.7em"><sup>*</sup>Equal Contribution.</a>
    <br>
    <span style="font-size: 0.8em; margin-top: 0.5em">
      <a><sup>1</sup>ByteDance</a>
      <a><sup>2</sup>Beihang University</a>
      <a><sup>3</sup>National University of Singapore</a>
    </span>
  </p>

  <font size="+1">
    <p style="text-align: center;" class="serif">
      <a href="https://arxiv.org/abs/2307.04725" target="_blank" style="font-weight: bold;">[Paper]</a>&nbsp;&nbsp;&nbsp;&nbsp;  
      <a href="https://photoverse2d.github.io/" target="_blank" style="font-weight: bold;">[Code (Coming soon)]</a>&nbsp;&nbsp;&nbsp;&nbsp;
      <a href="#bibtex" style="font-weight: bold;">[BibTeX]</a>
    </p><br>
  </font>
<!-- todo arxiv -->

<img class="summary-img" src="figs/res1-v3.png" style="width:90%;"> <br>
</div>

<div class="content">
  <p style="text-align:left; font-size: 2em; font-weight: bold" class="serif">Methodology</p>
  <p style="font-size: 1.2em" class="serif">
    Personalized text-to-image generation has emerged as a powerful and sought-after tool, empowering users to create customized images based on their specific concepts and prompts. However, existing approaches to personalization encounter multiple challenges, including long tuning times, large storage requirements, the necessity for multiple input images per identity, and limitations in preserving identity and editability.<br><br>
    
    To address these obstacles, we present PhotoVerse, an innovative methodology that incorporates a dual-branch conditioning mechanism in both text and image domains, providing effective control over the image generation process. 
    Furthermore, we introduce facial identity loss as a novel component to enhance the preservation of identity during training. Remarkably, our proposed PhotoVerse eliminates the need for test time tuning and relies solely on a single facial photo of the target identity, significantly reducing the resource cost associated with image generation. After a single training phase, our approach enables generating high-quality images within only a few seconds. Moreover, our method can produce diverse images that encompass various scenes and styles. 
  </p>
  <img class="summary-img" src="figs/framework.png" style="width:50%;"> <br>
</div>


<div class="content">
  <p style="text-align:left; font-size: 2em; font-weight: bold" class="serif">Gallery</p>
  <p style="font-size: 1.2em" class="serif">
    Here we present the highest-quality generated results achieved by leveraging a single reference image and a variety of prompts.<br>
    <!-- We recommend users visit our github repo and play with our pre-trained weights. -->
   <img class="summary-img" src="figs/results/supp-res1.png" style="width:90%;"> <br>
   <img class="summary-img" src="figs/results/supp-res2.png" style="width:90%;"> <br>
   <img class="summary-img" src="figs/results/supp-res3.png" style="width:90%;"> <br>
</div>


</div>

<div class="content" id="bibtex">
  <p style="text-align:left; font-size: 2em; font-weight: bold" class="serif">BibTeX</p>
  <!-- <span class="serif" style="color:red;"> (Coming Soon)</span> -->
  <code> @misc{guo2023animatediff,<br>
  &nbsp;&nbsp;title={PhotoVerse: Tuning-Free Image Customization with Text-to-Image Diffusion Models},<br>
  &nbsp;&nbsp;author={Li Chen, Mengyi Zhao, Yiheng Liu, Mingxu Ding, Yangyang Song, Shizun Wang, Xu Wang, Hao Yang, Jing Liu, Kang Du, Min Zheng},<br>
  &nbsp;&nbsp;booktitle={arXiv preprint arxiv:2307.04725},<br>
  &nbsp;&nbsp;year={2023},<br>
  &nbsp;&nbsp;archivePrefix={arXiv},<br>
  &nbsp;&nbsp;primaryClass={cs.CV}<br>
  } </code> 
</div>

<div class="content">
  <p class="serif">
    Project page template is borrowed from <a href="https://animatediff.github.io/">AnimateDiff</a>.<br>
    If you want an image removed from this page or have other requests, please contact us at <a href="mailto:zhaomengyi@buaa.edu.cn">zhaomengyi@buaa.edu.cn
  </p>
</div>

</body>

<script>
var videos = document.getElementsByClassName("clickplay");
for (var i = 0; i < videos.length; i++) {
  videos[i].addEventListener("click", function() {
    this.play();
  });
  videos[i].addEventListener("ended", function() {
    this.pause();
    this.currentTime = 0;
  });
}
</script>

</html>
